{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmBDe10tReVf"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8p0JFbsQiOW"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile('images/images.tgz'):\n",
        "  !mkdir images\n",
        "  !wget --no-check-certificate 'https://www.hep.phy.cam.ac.uk/~lwhitehead/neutrino_images_with_nc.tgz' -O images/images.tgz\n",
        "  !tar -xzf images/images.tgz -C images/\n",
        "\n",
        "# Work out the number of classes form the directory structure\n",
        "root_dir = 'images/'\n",
        "dir_contents = os.listdir(root_dir)\n",
        "num_classes = sum(os.path.isdir(os.path.join(root_dir, item)) for item in dir_contents)\n",
        "\n",
        "print('Dataset consists of', num_classes, 'classes')\n",
        "\n",
        "class_names = ['CC numu', 'CC nue', 'NC']\n",
        "for c in range(num_classes):\n",
        "  print('Number of',class_names[c],'images:')\n",
        "  !ls -1 images/$c/*.png | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1hNd2AhQ-vd"
      },
      "outputs": [],
      "source": [
        "# Batch size is the number of images processed in parallel\n",
        "batch_size = 32\n",
        "\n",
        "# The images have actual size 224 x 224, but I am downsampling\n",
        "# by a factor of two in order to reduce the run time\n",
        "img_height = 112\n",
        "img_width = 112\n",
        "\n",
        "# Let's make use. of tensorflow dataset objects. They let us\n",
        "# create a dataset from a directory of images\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  'images',\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=42,\n",
        "  color_mode=\"rgb\",\n",
        "  label_mode=\"categorical\",\n",
        "  shuffle=True,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  'images',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=42,\n",
        "  color_mode=\"rgb\",\n",
        "  label_mode=\"categorical\",\n",
        "  shuffle=True,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "# These images have all three views stacked. For simplicity extract the w view\n",
        "def extract_w_channel(image, label):\n",
        "    w_channel = image[:, :, :, 2]  # Assuming images are in RGB format\n",
        "    # Reshape to add a channel dimension\n",
        "    w_channel = tf.expand_dims(w_channel, axis=-1)\n",
        "    return w_channel, label\n",
        "\n",
        "# Apply the function to the dataset\n",
        "train_ds = train_ds.map(extract_w_channel)\n",
        "val_ds = val_ds.map(extract_w_channel)\n",
        "\n",
        "img_shape = None\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(1):\n",
        "        img_shape = images[i].numpy().shape\n",
        "        print(\"Image shape =\", img_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoypja4yVuZc"
      },
      "outputs": [],
      "source": [
        "# For simplicity I will use the keras Sequential model for the MLP\n",
        "mlp_model = tf.keras.Sequential()\n",
        "mlp_model.add(tf.keras.Input(shape=img_shape))\n",
        "mlp_model.add(tf.keras.layers.Flatten())\n",
        "mlp_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "mlp_model.add(tf.keras.layers.Dropout(0.5))\n",
        "mlp_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "mlp_model.add(tf.keras.layers.Dropout(0.5))\n",
        "mlp_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "mlp_model.add(tf.keras.layers.Dropout(0.5))\n",
        "mlp_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "mlp_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "571klltQXIBz"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "learning_rate = 0.001\n",
        "optimiser = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "mlp_model.compile(optimizer=optimiser, loss=loss_fn, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIszDWOTYDoa"
      },
      "outputs": [],
      "source": [
        "mlp_model.fit(train_ds, validation_data=val_ds, epochs=10,\n",
        "          verbose=1, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN91UFglYUnL"
      },
      "outputs": [],
      "source": [
        "cnn_model = tf.keras.Sequential()\n",
        "cnn_model.add(tf.keras.Input(shape=img_shape))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(64, (5,5), (2,2), activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(64, (5,5), (2,2), activation='relu'))\n",
        "cnn_model.add(tf.keras.layers.Dropout(0.25))\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "cnn_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNS2RqcpaNoe"
      },
      "outputs": [],
      "source": [
        "cnn_model.compile(optimizer=optimiser, loss=loss_fn, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3IDm4yOankA"
      },
      "outputs": [],
      "source": [
        "cnn_model.fit(train_ds, validation_data=val_ds, epochs=2,\n",
        "          verbose=1, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpExLwH1araE"
      },
      "outputs": [],
      "source": [
        "# Make a list of incorrect classifications\n",
        "incorrect_indices = []\n",
        "\n",
        "batch_ds = val_ds.take(1)\n",
        "\n",
        "for images, labels in batch_ds:\n",
        "  predictions = cnn_model.predict(images)\n",
        "\n",
        "  for i in range(len(labels)):\n",
        "    prediction = np.argmax(predictions[i])\n",
        "    truth = np.argmax(labels[i])\n",
        "    if prediction != truth:\n",
        "      incorrect_indices.append([images[i], prediction, truth])\n",
        "\n",
        "print('Number of images that were incorrectly classified =',len(incorrect_indices))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plot\n",
        "\n",
        "# Now you can modify this part to draw different images from the failures list\n",
        "# You can change the value of im to look at different failures\n",
        "im = 0\n",
        "image_to_plot = incorrect_indices[im][0]\n",
        "image_to_plot = np.clip(image_to_plot, 0.0, 50.0)\n",
        "fig, ax = plot.subplots(1, 1)\n",
        "print('Incorrect classification for image',im,\n",
        "      ': predicted =',incorrect_indices[im][1],\n",
        "      'with true =',incorrect_indices[im][2])\n",
        "ax.imshow(image_to_plot)"
      ],
      "metadata": {
        "id": "eVQmAQDNADxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzfEoTlOM5G0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
