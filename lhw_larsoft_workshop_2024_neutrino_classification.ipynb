{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this note book we will attempt to classify a set of neutrino interactions as either CC $\\nu_\\mu$, CC $\\nu_e$ and NC $\\nu$ events"
      ],
      "metadata": {
        "id": "onkmwD9vwFWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmBDe10tReVf"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below downloads the sample of genie neutrino events. It will save the `.png` images to the `images` directory. It contains equal numbers of CC $\\nu_\\mu$, CC $\\nu_e$ and NC $\\nu$ interactions."
      ],
      "metadata": {
        "id": "F54LecKAtzZ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8p0JFbsQiOW"
      },
      "outputs": [],
      "source": [
        "if not os.path.isfile('images/images.tgz'):\n",
        "  !mkdir images\n",
        "  !wget --no-check-certificate 'https://www.hep.phy.cam.ac.uk/~lwhitehead/genie_neutrino_images.tgz' -O images/images.tgz\n",
        "  !tar -xzf images/images.tgz -C images/\n",
        "\n",
        "# Work out the number of classes form the directory structure\n",
        "root_dir = 'images/'\n",
        "dir_contents = os.listdir(root_dir)\n",
        "num_classes = sum(os.path.isdir(os.path.join(root_dir, item)) for item in dir_contents)\n",
        "\n",
        "print('Dataset consists of', num_classes, 'classes')\n",
        "\n",
        "class_names = ['CC numu', 'CC nue', 'NC']\n",
        "for c in range(num_classes):\n",
        "  print('Number of',class_names[c],'images:')\n",
        "  !ls -1 images/$c/*.png | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block of code automatically builds the datasets direction from the `images` directory, making use of the folder structure to extract the correct truth label for each image."
      ],
      "metadata": {
        "id": "LbUsZL7euOEm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1hNd2AhQ-vd"
      },
      "outputs": [],
      "source": [
        "# Batch size is the number of images processed in parallel\n",
        "batch_size = 32\n",
        "\n",
        "# The images have actual size 224 x 224, but I am downsampling\n",
        "# by a factor of two in order to reduce the run time\n",
        "img_height = 112\n",
        "img_width = 112\n",
        "\n",
        "# Let's make use. of tensorflow dataset objects. They let us\n",
        "# create a dataset from a directory of images\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  'images',\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=42,\n",
        "  color_mode=\"rgb\",\n",
        "  label_mode=\"categorical\",\n",
        "  shuffle=True,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  'images',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=42,\n",
        "  color_mode=\"rgb\",\n",
        "  label_mode=\"categorical\",\n",
        "  shuffle=True,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "# These images have all three views stacked. For simplicity extract the w view\n",
        "def extract_w_channel(image, label):\n",
        "    w_channel = image[:, :, :, 2]\n",
        "    # Reshape to add a channel dimension\n",
        "    w_channel = tf.expand_dims(w_channel, axis=-1)\n",
        "    return w_channel, label\n",
        "\n",
        "# Apply the function to the dataset\n",
        "train_ds = train_ds.map(extract_w_channel)\n",
        "val_ds = val_ds.map(extract_w_channel)\n",
        "\n",
        "img_shape = None\n",
        "for images, _ in train_ds.take(1):\n",
        "    img_shape = images[0].numpy().shape\n",
        "    print(\"Image shape =\", img_shape)\n",
        "    n_plots=3\n",
        "    fig, ax = plt.subplots(1, n_plots)\n",
        "    for plot_number in range (0, n_plots):\n",
        "        ax[plot_number].imshow(images[plot_number])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can go ahead and make a CNN as we did in the first tutorial. Feel free to use the architecture that you used in the first tutorial as a base - the comments below follow that architecture"
      ],
      "metadata": {
        "id": "wXoTXLpou4mc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoypja4yVuZc"
      },
      "outputs": [],
      "source": [
        "# Create your CNN model here\n",
        "input_layer = keras.layers.Input(img_shape)\n",
        "# First layer: 2D convolution with 32 filters of size (3,3) and relu activation\n",
        "x = None(...)(input_layer)\n",
        "# Second layer: 2D max pooling layer to downsample by a factor of 2 in both dimensions\n",
        "x = None(...)(x)\n",
        "# Third layer: dropout with 25% of neurons disabled\n",
        "x = None(...)(x)\n",
        "# Fourth layer: flatten the output into 1D for input to a dense layer\n",
        "x = None(...)(x)\n",
        "# Fifth layer: dense layer for classification into the number of classes\n",
        "x = None(...)(x)\n",
        "cnn_model = keras.Model(input_layer, x)\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "571klltQXIBz"
      },
      "outputs": [],
      "source": [
        "# Compile the model and set up the optimise and loss function required\n",
        "learning_rate = 0.001\n",
        "optimiser = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "cnn_model.compile(optimizer=optimiser, loss=loss_fn, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's train the CNN and see how it does"
      ],
      "metadata": {
        "id": "HJgnyClz6FuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(train_ds, validation_data=val_ds, epochs=1,\n",
        "          verbose=1, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "IacbZkfX6HxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quick function to get the indices of events that were wrongly classified"
      ],
      "metadata": {
        "id": "fDcMsO0b3z2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpExLwH1araE"
      },
      "outputs": [],
      "source": [
        "# Make a list of incorrect classifications\n",
        "def get_incorrect_classifications(model, dataset):\n",
        "  incorrect_indices = []\n",
        "\n",
        "  batch_ds = dataset.take(5)\n",
        "\n",
        "  for images, labels in batch_ds:\n",
        "    predictions = model.predict(images)\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "      prediction = np.argmax(predictions[i])\n",
        "      truth = np.argmax(labels[i])\n",
        "      if prediction != truth:\n",
        "        incorrect_indices.append([images[i], prediction, truth])\n",
        "\n",
        "  print('Number of images that were incorrectly classified =',len(incorrect_indices))\n",
        "  return incorrect_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to draw a wrongly classified event so that we can have a look at it"
      ],
      "metadata": {
        "id": "JJt4pwV64ZDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now you can modify this part to draw different images from the failures list\n",
        "# You can change the value of im to look at different failures\n",
        "def draw_event(incorrect_indices, index):\n",
        "  image_to_plot = incorrect_indices[index][0]\n",
        "  image_to_plot = np.clip(image_to_plot, 0.0, 50.0)\n",
        "  fig, ax = plt.subplots(1, 1)\n",
        "  print('Incorrect classification for image',index,\n",
        "        ': predicted =',incorrect_indices[index][1],\n",
        "        'with true =',incorrect_indices[index][2])\n",
        "  ax.imshow(image_to_plot)"
      ],
      "metadata": {
        "id": "eVQmAQDNADxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the failures\n",
        "incorrect_indices = get_incorrect_classifications(cnn_model, val_ds)"
      ],
      "metadata": {
        "id": "bbcthnY2_VF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have a look at the failures\n",
        "draw_event(incorrect_indices, 0)"
      ],
      "metadata": {
        "id": "R6lb2T_6A6mz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
